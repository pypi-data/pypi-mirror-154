Metadata-Version: 2.1
Name: trecover
Version: 1.0.2
Summary: A python library for training a Transformer neural network to solve the Running Key Cipher, widely known in the field of cryptography.
Home-page: https://github.com/alex-snd/TRecover
Author: Alexander Shulga
Author-email: alexandershulga.sh@gmail.com
License: Apache License 2.0
Keywords: Deep Learning,Machine Learning,Transformers,NLP,Cryptography,Keyless Reading,TRecover,Text Recovery,PyTorch
Classifier: Development Status :: 4 - Beta
Classifier: Environment :: Console
Classifier: Environment :: GPU :: NVIDIA CUDA
Classifier: Environment :: Web Environment
Classifier: Framework :: AsyncIO
Classifier: Framework :: Celery
Classifier: Framework :: FastAPI
Classifier: Framework :: Jupyter
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Natural Language :: English
Classifier: Operating System :: MacOS
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: Unix
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Education
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Security
Classifier: Topic :: Security :: Cryptography
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: black (==22.3.0)
Requires-Dist: docker (==5.0.3)
Requires-Dist: psutil (==5.8.0)
Requires-Dist: python-dotenv (==0.19.2)
Requires-Dist: requests (==2.25.1)
Requires-Dist: rich (==10.15.1)
Requires-Dist: toml (==0.10.2)
Requires-Dist: click (==8.0.4)
Requires-Dist: typer[all] (==0.4.0)
Provides-Extra: api
Requires-Dist: celery[redis] (==5.2.2) ; extra == 'api'
Requires-Dist: pydantic (==1.8.2) ; extra == 'api'
Requires-Dist: fastapi (==0.68.1) ; extra == 'api'
Requires-Dist: uvicorn (==0.15.0) ; extra == 'api'
Provides-Extra: dashboard
Requires-Dist: streamlit (==1.7.0) ; extra == 'dashboard'
Requires-Dist: numpy (==1.21) ; extra == 'dashboard'
Provides-Extra: demo
Requires-Dist: celery[redis] (==5.2.2) ; extra == 'demo'
Requires-Dist: fastapi (==0.68.1) ; extra == 'demo'
Requires-Dist: numpy (==1.21) ; extra == 'demo'
Requires-Dist: pydantic (==1.8.2) ; extra == 'demo'
Requires-Dist: streamlit (==1.7.0) ; extra == 'demo'
Requires-Dist: torch (==1.9.0) ; extra == 'demo'
Requires-Dist: uvicorn (==0.15.0) ; extra == 'demo'
Provides-Extra: dev
Requires-Dist: alembic (==1.4.1) ; extra == 'dev'
Requires-Dist: celery[redis] (==5.2.2) ; extra == 'dev'
Requires-Dist: docker (==5.0.3) ; extra == 'dev'
Requires-Dist: fastapi (==0.68.1) ; extra == 'dev'
Requires-Dist: mlflow (==1.23.1) ; extra == 'dev'
Requires-Dist: numpy (==1.21) ; extra == 'dev'
Requires-Dist: psutil (==5.8.0) ; extra == 'dev'
Requires-Dist: pydantic (==1.8.2) ; extra == 'dev'
Requires-Dist: python-dotenv (==0.19.2) ; extra == 'dev'
Requires-Dist: requests (==2.25.1) ; extra == 'dev'
Requires-Dist: rich (==10.15.1) ; extra == 'dev'
Requires-Dist: streamlit (==1.7.0) ; extra == 'dev'
Requires-Dist: toml (==0.10.2) ; extra == 'dev'
Requires-Dist: torch (==1.9.0) ; extra == 'dev'
Requires-Dist: pytorch-lightning (==1.6.0) ; extra == 'dev'
Requires-Dist: typer[all] (==0.4.0) ; extra == 'dev'
Requires-Dist: uvicorn (==0.15.0) ; extra == 'dev'
Requires-Dist: wandb (==0.12.7) ; extra == 'dev'
Provides-Extra: docs
Requires-Dist: mkdocs (==1.3.0) ; extra == 'docs'
Requires-Dist: mkdocs-material (==8.3.3) ; extra == 'docs'
Requires-Dist: mkdocstrings[python] (==0.18.1) ; extra == 'docs'
Requires-Dist: mkdocs-macros-plugin (==0.7.0) ; extra == 'docs'
Provides-Extra: standalone
Requires-Dist: torch (==1.9.0) ; extra == 'standalone'
Requires-Dist: celery[redis] (==5.2.2) ; extra == 'standalone'
Requires-Dist: pydantic (==1.8.2) ; extra == 'standalone'
Requires-Dist: streamlit (==1.7.0) ; extra == 'standalone'
Requires-Dist: numpy (==1.21) ; extra == 'standalone'
Requires-Dist: fastapi (==0.68.1) ; extra == 'standalone'
Requires-Dist: uvicorn (==0.15.0) ; extra == 'standalone'
Provides-Extra: train
Requires-Dist: alembic (==1.4.1) ; extra == 'train'
Requires-Dist: mlflow (==1.23.1) ; extra == 'train'
Requires-Dist: numpy (==1.21) ; extra == 'train'
Requires-Dist: torch (==1.9.0) ; extra == 'train'
Requires-Dist: pytorch-lightning (==1.6.0) ; extra == 'train'
Requires-Dist: wandb (==0.12.7) ; extra == 'train'
Provides-Extra: worker
Requires-Dist: celery[redis] (==5.2.2) ; extra == 'worker'
Requires-Dist: torch (==1.9.0) ; extra == 'worker'

<h1 align="center">Welcome to Text Recovery Project üëã</h1>
<p align="center">
  A python library for training a Transformer neural network to solve the <a href="https://en.wikipedia.org/wiki/Running_key_cipher">Running Key Cipher</a>, widely known in the field of cryptography.
</p>

![Preview Animation](../assets/preview_animation.gif?raw=true)
  
<p align="center">
  <a href="https://huggingface.co/spaces/alex-snd/TRecover">
    <img src="https://img.shields.io/badge/demo-%F0%9F%A4%97%20Hugging%20Face-blue?color=%2348466D" alt="Hugging Face demo"/>
  </a>
  <a href="https://alex-snd.github.io/TRecover">
    <img src="https://img.shields.io/badge/docs-MkDocs-blue.svg?color=%2348466D" alt="MkDocs link"/>
  </a>
  <img src="https://img.shields.io/badge/python-v3.8.5-blue.svg?color=%2348466D" alt="Python version"/>
  <a href="https://colab.research.google.com/github/alex-snd/TRecover/blob/master/notebooks/TRecover-train-alone.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg?color=%2348466D" alt="Open In Colab"/>
  </a>
  <a href="https://badge.fury.io/py/trecover">
    <img src="https://img.shields.io/pypi/v/trecover?color=%2348466D" alt="PyPI version"/>
  </a>
  <img src="https://static.pepy.tech/personalized-badge/trecover?period=total&units=international_system&left_color=grey&right_color=%2348466D&left_text=pypi downloads" alt="PyPi Downloads"/>
  <a href="https://github.com/alex-snd/TRecover/blob/master/LICENSE">
    <img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?color=%2348466D" alt="License Apache 2.0"/>
  </a>
</p>

## üöÄ Objective
The main goal of the project is to study the possibility of using Transformer neural network to ‚Äúread‚Äù meaningful text in columns that can be compiled for a [Running Key Cipher](https://en.wikipedia.org/wiki/Running_key_cipher). You can read more about the problem [here](https://alex-snd.github.io/TRecover/objective/).

In addition, the second rather fun üòÖ goal is to train a large enough model so that it can handle the case described below.
Let there be an original sentence:

>Hello, my name is ***Zendaya*** Maree Stoermer Coleman but you can just call me ***Zendaya***.

The columns for this sentence will be compiled in such a way that the last seven contain from ten to thirteen letters of the English alphabet, and all the others from two to five. Thus, the last seven characters will be much harder to "read" compared to the rest. However, we can guess from the meaning of the sentence that this is the name ***Zendaya***.
In other words, the goal is also to train a model that can understand and correctly ‚Äúread‚Äù the last word.




## ‚öô Installation
Trecover requires Python 3.8 or higher and supports both Windows and Linux platforms.
1. Clone the repository:
```shell
git clone https://github.com/alex-snd/TRecover.git  && cd trecover
```

2. Create a virtual environment:
    * Windows:
    ```shell
    python -m venv venv
    ```
    * Linux:
    ```shell
    python3 -m venv venv
    ```
3. Activate the virtual environment:
    * Windows:
    ```shell
    venv\Scripts\activate.bat
    ```
    * Linux:
    ```shell
    source venv/bin/activate
    ```

5. Install the package inside this virtual environment:
    * Just to run the demo:
    ```shell
    pip install -e ".[demo]"
    ```
    * To train the Transformer:
    ```shell
    pip install -e ".[train]"
    ```
    * For development and training:
    ```shell
    pip install -e ".[dev]"
    ```
    
6. Initialize project's environment:
   ```shell
   trecover init
   ```
   For more options use:
   ```shell
   trecover init --help
   ```


## üëÄ Demo
* ü§ó Hugging Face <br>
  You can play with a pre-trained model hosted [here](https://huggingface.co/spaces/alex-snd/TRecover).
* üê≥ Docker Compose<br>
  * Pull from Docker Hub:
    ```shell
    docker-compose -f docker/compose/scalable-service.yml up
    ```
  * Build from source:
    ```shell
    docker-compose -f docker/compose/scalable-service-build.yml up
    ```
* üíª Local (requires docker) <br>
  * Download pretrained model:
    ```shell
    trecover download artifacts
    ```
  * Launch the service:
    ```shell
    trecover up
    ```



## üóÉÔ∏è Data
The [WikiText](https://huggingface.co/datasets/wikitext) and [WikiQA](https://huggingface.co/datasets/wiki_qa) datasets 
were used to train the model, from which all characters except English letters were removed.<br>
You can download the cleaned dataset:
```shell
trecover download data
```


## üí™ Train
To quickly start training the model, open the [Jupyter Notebook](https://colab.research.google.com/github/alex-snd/TRecover/blob/master/notebooks/TRecover-train-alone.ipynb).


* üï∏Ô∏è Distributed <br>
  TODO
* üíª Local <br>
  After the dataset is loaded, you can start training the model:
  ```
  trecover train local \
  --project-name {project_name} \
  --exp-mark {exp_mark} \
  --train-dataset-size {train_dataset_size} \
  --val-dataset-size {val_dataset_size} \
  --vis-dataset-size {vis_dataset_size} \
  --test-dataset-size {test_dataset_size} \
  --batch-size {batch_size} \
  --n-workers {n_workers} \
  --min-noise {min_noise} \
  --max-noise {max_noise} \
  --lr {lr} \
  --n-epochs {n_epochs} \
  --epoch-seek {epoch_seek} \
  --accumulation-step {accumulation_step} \
  --penalty-coefficient {penalty_coefficient} \

  --pe-max-len {pe_max_len} \
  --n-layers {n_layers} \
  --d-model {d_model} \
  --n-heads {n_heads} \
  --d-ff {d_ff} \
  --dropout {dropout}
  ```
  For more information use `trecover train local --help`


## ‚úîÔ∏è Related work
TODO: what was done, tech stack.


## ü§ù Contributing
Contributions, issues and feature requests are welcome.<br />
Feel free to check [issues page](https://github.com/alex-snd/TRecover/issues) if you want to contribute.


## üëè Show your support
Please don't hesitate to ‚≠êÔ∏è this repository if you find it cool!


## üìú License
Copyright ¬© 2022 [Alexander Shulga](https://www.linkedin.com/in/alex-snd).<br />
This project is [Apache 2.0](https://github.com/alex-snd/TRecover/blob/master/LICENSE) licensed.

